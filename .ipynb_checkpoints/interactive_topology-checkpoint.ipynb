{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d30692-14db-4093-931c-ddac4047f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import alphashape\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import MultiPoint, LineString\n",
    "from shapely.ops import unary_union\n",
    "import cv2  # For video writing\n",
    "import tempfile\n",
    "\n",
    "# --- Loading functions ---\n",
    "def load_custom_graph(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    num_nodes, is_directed = map(int, lines[0].strip().split(','))\n",
    "    G = nx.DiGraph() if is_directed else nx.Graph()\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "\n",
    "    edge_pattern = re.compile(r\"\\((\\d+),(\\d+),([0-9.]+)\\)\")\n",
    "    for line in lines[1:]:\n",
    "        match = edge_pattern.match(line.strip())\n",
    "        if match:\n",
    "            u, v, w = int(match[1]), int(match[2]), float(match[3])\n",
    "            G.add_edge(u, v, weight=w)\n",
    "    return G, num_nodes\n",
    "\n",
    "def load_opinions(filepath):\n",
    "    node_values = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                node, val = int(parts[0]), float(parts[1])\n",
    "                node_values[node] = val\n",
    "    return node_values\n",
    "\n",
    "def load_graph_series(folder_path):\n",
    "    graph_files = sorted(f for f in os.listdir(folder_path) if f.endswith('.graph'))\n",
    "    graphs = []\n",
    "    opinions_list = []\n",
    "    for gf in graph_files:\n",
    "        graph_path = os.path.join(folder_path, gf)\n",
    "        opin_path = graph_path.replace('.graph', '.opinions')\n",
    "        G, num_nodes = load_custom_graph(graph_path)\n",
    "        node_values = load_opinions(opin_path)\n",
    "        nx.set_node_attributes(G, node_values, name='value')\n",
    "        graphs.append(G)\n",
    "        opinions_list.append(node_values)\n",
    "    return graphs, opinions_list\n",
    "\n",
    "# --- Clustering and layout ---\n",
    "def custom_cluster_detection(G, node_values, layout):\n",
    "    nodes = list(G.nodes)\n",
    "    clusters = []\n",
    "    unvisited = set(nodes)\n",
    "    while unvisited:\n",
    "        current = unvisited.pop()\n",
    "        cluster = {current}\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            to_check = unvisited.copy()\n",
    "            for other in to_check:\n",
    "                all_dist_ok = True\n",
    "                all_val_ok = True\n",
    "                for cnode in cluster:\n",
    "                    pos_c = layout[cnode]\n",
    "                    pos_o = layout[other]\n",
    "                    dist = np.linalg.norm(np.array(pos_c) - np.array(pos_o))\n",
    "                    if dist >= 3:\n",
    "                        all_dist_ok = False\n",
    "                        break\n",
    "                for cnode in cluster:\n",
    "                    if abs(node_values[cnode] - node_values[other]) >= 0.3:\n",
    "                        all_val_ok = False\n",
    "                        break\n",
    "                if all_dist_ok and all_val_ok:\n",
    "                    cluster.add(other)\n",
    "                    unvisited.remove(other)\n",
    "                    changed = True\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    # Filter clusters to have minimum size 3\n",
    "    clusters = [c for c in clusters if len(c) >= 3]\n",
    "\n",
    "    cluster_map = {}\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        for n in cluster:\n",
    "            cluster_map[n] = i\n",
    "    # For nodes not assigned (small clusters), assign -1 (or keep as is)\n",
    "    for n in G.nodes:\n",
    "        if n not in cluster_map:\n",
    "            cluster_map[n] = -1\n",
    "    return cluster_map\n",
    "\n",
    "def detect_clusters_custom(graphs, opinions_list):\n",
    "    cluster_assignments = []\n",
    "    global_layouts = []\n",
    "    for i, G in enumerate(graphs):\n",
    "        layout = nx.spring_layout(G, weight='weight', k=0.5, iterations=50)\n",
    "        node_values = opinions_list[i]\n",
    "        cluster_map = custom_cluster_detection(G, node_values, layout)\n",
    "        cluster_assignments.append(cluster_map)\n",
    "        global_layouts.append(layout)\n",
    "    return cluster_assignments, global_layouts\n",
    "\n",
    "def avoid_node_overlap(layout, node_sizes, min_dist_factor=2.5, iterations=50):\n",
    "    positions = {n: np.array(pos) for n, pos in layout.items()}\n",
    "    nodes = list(layout.keys())\n",
    "    for _ in range(iterations):\n",
    "        moved = False\n",
    "        for i, n1 in enumerate(nodes):\n",
    "            for n2 in nodes[i+1:]:\n",
    "                pos1, pos2 = positions[n1], positions[n2]\n",
    "                diff = pos2 - pos1\n",
    "                dist = np.linalg.norm(diff)\n",
    "                min_dist = (node_sizes.get(n1, 10) + node_sizes.get(n2, 10)) * min_dist_factor\n",
    "                if dist < min_dist and dist > 1e-6:\n",
    "                    overlap = min_dist - dist\n",
    "                    shift = (overlap / 2) * (diff / dist)\n",
    "                    positions[n1] -= shift\n",
    "                    positions[n2] += shift\n",
    "                    moved = True\n",
    "        if not moved:\n",
    "            break\n",
    "    return {n: pos.tolist() for n, pos in positions.items()}\n",
    "\n",
    "def scale_and_fit_layout(layout, width=1280, height=720, margin=50):\n",
    "    pos_arr = np.array(list(layout.values()))\n",
    "    min_xy = pos_arr.min(axis=0)\n",
    "    max_xy = pos_arr.max(axis=0)\n",
    "    size = max_xy - min_xy\n",
    "    scale_x = (width - 2 * margin) / size[0] if size[0] > 0 else 1.0\n",
    "    scale_y = (height - 2 * margin) / size[1] if size[1] > 0 else 1.0\n",
    "    scale = min(scale_x, scale_y)\n",
    "    new_layout = {}\n",
    "    for n, pos in layout.items():\n",
    "        norm_pos = (np.array(pos) - min_xy) * scale + margin\n",
    "        new_layout[n] = norm_pos.tolist()\n",
    "    return new_layout\n",
    "\n",
    "def generate_layouts(graphs, cluster_assignments, opinions_list):\n",
    "    layouts = []\n",
    "    for t, G in enumerate(graphs):\n",
    "        node_values = opinions_list[t]\n",
    "        cluster_map = cluster_assignments[t]\n",
    "        cluster_positions = {}\n",
    "        for cluster_id in set(cluster_map.values()):\n",
    "            if cluster_id == -1:\n",
    "                # Single nodes or small clusters left unclustered; layout individually\n",
    "                nodes = [n for n in G.nodes if cluster_map[n] == cluster_id]\n",
    "                for n in nodes:\n",
    "                    cluster_positions[n] = np.random.rand(2) * 10\n",
    "                continue\n",
    "            nodes = [n for n in G.nodes if cluster_map[n] == cluster_id]\n",
    "            subgraph = G.subgraph(nodes)\n",
    "            sublayout = nx.spring_layout(subgraph, weight='weight', k=0.5, iterations=50)\n",
    "            scale = 1.0\n",
    "            for n in sublayout:\n",
    "                sublayout[n] = scale * np.array(sublayout[n])\n",
    "            offset = np.random.rand(2) * 10\n",
    "            for n in sublayout:\n",
    "                sublayout[n] = sublayout[n] + offset\n",
    "            cluster_positions.update(sublayout)\n",
    "        node_sizes = {n: 10 * abs(node_values.get(n, 0)) + 20 for n in G.nodes}  # min 20 for size\n",
    "        layout_no_overlap = avoid_node_overlap(cluster_positions, node_sizes)\n",
    "        layout_scaled = scale_and_fit_layout(layout_no_overlap)\n",
    "        layouts.append(layout_scaled)\n",
    "    return layouts\n",
    "\n",
    "# --- Visual helpers ---\n",
    "def generate_alpha_boundary(points):\n",
    "    try:\n",
    "        shape = alphashape.alphashape(points, alpha=0.3)  # smoother\n",
    "        if isinstance(shape, Polygon):\n",
    "            shape = shape.buffer(25)  # increase padding around nodes\n",
    "            if shape.is_empty or not shape.exterior:\n",
    "                return []\n",
    "            x, y = shape.exterior.xy\n",
    "            return list(zip(x, y))\n",
    "    except Exception as e:\n",
    "        print(f\"Alpha shape error: {e}\")\n",
    "        return []\n",
    "    return []\n",
    "\n",
    "def bezier_curve_points(p0, p1, control, num=20):\n",
    "    points = []\n",
    "    for t in np.linspace(0, 1, num):\n",
    "        point = (1 - t) ** 2 * np.array(p0) + 2 * (1 - t) * t * np.array(control) + t ** 2 * np.array(p1)\n",
    "        points.append(point.tolist())\n",
    "    return points\n",
    "\n",
    "def build_curvy_edge_traces(G, layout):\n",
    "    traces = []\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        weight = d.get('weight', 1.0)\n",
    "        edge_width = 3 + (1 - weight) * 7  # from 3 to 10\n",
    "\n",
    "        p0 = layout[u]\n",
    "        p1 = layout[v]\n",
    "        mid = (np.array(p0) + np.array(p1)) / 2\n",
    "        vec = np.array(p1) - np.array(p0)\n",
    "        perp = np.array([-vec[1], vec[0]])\n",
    "        norm_perp = perp / (np.linalg.norm(perp) + 1e-6)\n",
    "        offset = norm_perp * np.linalg.norm(vec) * 0.3\n",
    "        control = mid + offset\n",
    "        curve_points = bezier_curve_points(p0, p1, control)\n",
    "        xs, ys = zip(*curve_points)\n",
    "\n",
    "        trace = go.Scatter(\n",
    "            x=xs, y=ys,\n",
    "            mode='lines',\n",
    "            line=dict(color='rgba(150,150,150,0.7)', width=edge_width),\n",
    "            hoverinfo='none',\n",
    "            showlegend=False\n",
    "        )\n",
    "        traces.append(trace)\n",
    "    return traces\n",
    "\n",
    "def create_node_trace(G, layout, node_values, cluster_map):\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_color = []\n",
    "    node_size = []\n",
    "    for node in G.nodes():\n",
    "        pos = layout[node]\n",
    "        node_x.append(pos[0])\n",
    "        node_y.append(pos[1])\n",
    "        val = node_values.get(node, 0)\n",
    "        node_color.append(val)\n",
    "        # Node size between 20 and 40\n",
    "        size = 20 + (abs(val) * 20)\n",
    "        if size > 40:\n",
    "            size = 40\n",
    "        node_size.append(size)\n",
    "    trace = go.Scatter(\n",
    "        x=node_x, y=node_y,\n",
    "        mode='markers+text',\n",
    "        text=[str(n) for n in G.nodes()],\n",
    "        textposition=\"top center\",\n",
    "        marker=dict(\n",
    "            size=node_size,\n",
    "            color=node_color,\n",
    "            colorscale='RdBu',\n",
    "            cmin=-1, cmax=1,\n",
    "            line_width=1,\n",
    "            line_color='black'\n",
    "        )\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "def create_boundary_trace(points, cluster_id):\n",
    "    if not points:\n",
    "        return None\n",
    "    xs, ys = zip(*points)\n",
    "    trace = go.Scatter(\n",
    "        x=xs, y=ys,\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(0,200,0,0.15)',\n",
    "        line=dict(color='rgba(0,0,0,0)', width=0),\n",
    "        hoverinfo='skip',\n",
    "        showlegend=False,\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "\n",
    "def generate_minimal_alpha_boundary(cluster_nodes, G, layout, node_sizes, padding=5):\n",
    "    shapes = []\n",
    "\n",
    "    # Add node circles\n",
    "    for n in cluster_nodes:\n",
    "        center = layout[n]\n",
    "        radius = node_sizes.get(n, 10) / 2  # radius from diameter/size\n",
    "        circle = Point(center).buffer(radius)\n",
    "        shapes.append(circle)\n",
    "\n",
    "    # Add edges as thickened lines (buffered by edge thickness, say 1.5)\n",
    "    for u, v in G.subgraph(cluster_nodes).edges():\n",
    "        p0 = layout[u]\n",
    "        p1 = layout[v]\n",
    "        line = LineString([p0, p1])\n",
    "        # Buffer by small edge thickness (1.5 or smaller)\n",
    "        line_buffer = line.buffer(1.5)\n",
    "        shapes.append(line_buffer)\n",
    "\n",
    "    # Union all shapes\n",
    "    combined_shape = unary_union(shapes)\n",
    "\n",
    "    # Buffer by padding\n",
    "    hull = combined_shape.buffer(padding)\n",
    "\n",
    "    if hull.is_empty or not hull.exterior:\n",
    "        return []\n",
    "\n",
    "    x, y = hull.exterior.xy\n",
    "    return list(zip(x, y))\n",
    "\n",
    "\n",
    "def create_frame(G, layout, node_values, cluster_map):\n",
    "    fig = go.Figure()\n",
    "    clusters = {}\n",
    "    for n, c in cluster_map.items():\n",
    "        clusters.setdefault(c, []).append(n)\n",
    "\n",
    "    for c_id, nodes in clusters.items():\n",
    "        if c_id == -1:\n",
    "            # Skip small/unclustered nodes for boundary\n",
    "            continue\n",
    "        pts = [layout[n] for n in nodes]\n",
    "        boundary = boundary = generate_minimal_alpha_boundary(nodes, G, layout, padding=5)\n",
    "        btrace = create_boundary_trace(boundary, c_id)\n",
    "        if btrace:\n",
    "            fig.add_trace(btrace)\n",
    "\n",
    "    edge_traces = build_curvy_edge_traces(G, layout)\n",
    "    for etrace in edge_traces:\n",
    "        fig.add_trace(etrace)\n",
    "\n",
    "    node_trace = create_node_trace(G, layout, node_values, cluster_map)\n",
    "    fig.add_trace(node_trace)\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 1280]),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 720], scaleanchor=\"x\"),\n",
    "        plot_bgcolor='white',\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        width=1280,\n",
    "        height=720,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- Main ---\n",
    "def main(folder_path, output_video_path):\n",
    "    print(\"Loading graph series...\")\n",
    "    graphs, opinions_list = load_graph_series(folder_path)\n",
    "    print(f\"Loaded {len(graphs)} graphs.\")\n",
    "\n",
    "    print(\"Detecting clusters...\")\n",
    "    cluster_assignments, base_layouts = detect_clusters_custom(graphs, opinions_list)\n",
    "    print(\"Cluster detection done.\")\n",
    "\n",
    "    print(\"Generating layouts...\")\n",
    "    layouts = generate_layouts(graphs, cluster_assignments, opinions_list)\n",
    "    print(\"Layouts generated.\")\n",
    "\n",
    "    # Only generate the first frame\n",
    "    print(\"Generating initial frame only...\")\n",
    "    layout = layouts[0]\n",
    "    G = graphs[0]\n",
    "    node_values = opinions_list[0]\n",
    "    cluster_map = cluster_assignments[0]\n",
    "    fig = create_frame(G, layout, node_values, cluster_map)\n",
    "    fig.write_image(\"initial_frame.png\")\n",
    "    print(\"Initial frame saved as 'initial_frame.png'\")\n",
    "\n",
    "# Example usage:\n",
    "main('./simls_raw_data/2025-07-08_16-37-25', 'output.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "836ac4f0-2a35-4030-9c83-f5f43e0494f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph series...\n",
      "Loaded 73 graphs.\n",
      "Detecting clusters...\n",
      "Cluster detection done.\n",
      "Generating layouts...\n",
      "Layouts generated.\n",
      "Generating initial frame only...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiPolygon' object has no attribute 'exterior'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 329\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitial frame saved as \u001b[39m\u001b[33m'\u001b[39m\u001b[33minitial_frame.png\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./simls_raw_data/2025-07-08_16-37-25\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutput.mp4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 324\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(folder_path, output_video_path)\u001b[39m\n\u001b[32m    322\u001b[39m node_values = opinions_list[\u001b[32m0\u001b[39m]\n\u001b[32m    323\u001b[39m cluster_map = cluster_assignments[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m fig = \u001b[43mcreate_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m fig.write_image(\u001b[33m\"\u001b[39m\u001b[33minitial_frame.png\u001b[39m\u001b[33m\"\u001b[39m, width=\u001b[32m1280\u001b[39m, height=\u001b[32m720\u001b[39m, scale=\u001b[32m1\u001b[39m)\n\u001b[32m    326\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitial frame saved as \u001b[39m\u001b[33m'\u001b[39m\u001b[33minitial_frame.png\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 280\u001b[39m, in \u001b[36mcreate_frame\u001b[39m\u001b[34m(G, layout, node_values, cluster_map)\u001b[39m\n\u001b[32m    277\u001b[39m     clusters.setdefault(c, []).append(n)\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c_id, nodes \u001b[38;5;129;01min\u001b[39;00m clusters.items():\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     boundary = \u001b[43mgenerate_minimal_alpha_boundary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     btrace = create_boundary_trace(boundary, c_id)\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m btrace:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 195\u001b[39m, in \u001b[36mgenerate_minimal_alpha_boundary\u001b[39m\u001b[34m(cluster_nodes, G, layout, node_sizes, padding)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Buffer by padding\u001b[39;00m\n\u001b[32m    193\u001b[39m hull = combined_shape.buffer(padding)\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hull.is_empty \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mhull\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexterior\u001b[49m:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[32m    198\u001b[39m x, y = hull.exterior.xy\n",
      "\u001b[31mAttributeError\u001b[39m: 'MultiPolygon' object has no attribute 'exterior'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import alphashape\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# --- Loading functions ---\n",
    "def load_custom_graph(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    num_nodes, is_directed = map(int, lines[0].strip().split(','))\n",
    "    G = nx.DiGraph() if is_directed else nx.Graph()\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "\n",
    "    edge_pattern = re.compile(r\"\\((\\d+),(\\d+),([0-9.]+)\\)\")\n",
    "    for line in lines[1:]:\n",
    "        match = edge_pattern.match(line.strip())\n",
    "        if match:\n",
    "            u, v, w = int(match[1]), int(match[2]), float(match[3])\n",
    "            G.add_edge(u, v, weight=w)\n",
    "    return G, num_nodes\n",
    "\n",
    "def load_opinions(filepath):\n",
    "    node_values = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                node, val = int(parts[0]), float(parts[1])\n",
    "                node_values[node] = val\n",
    "    return node_values\n",
    "\n",
    "def load_graph_series(folder_path):\n",
    "    graph_files = sorted(f for f in os.listdir(folder_path) if f.endswith('.graph'))\n",
    "    graphs = []\n",
    "    opinions_list = []\n",
    "    for gf in graph_files:\n",
    "        graph_path = os.path.join(folder_path, gf)\n",
    "        opin_path = graph_path.replace('.graph', '.opinions')\n",
    "        G, num_nodes = load_custom_graph(graph_path)\n",
    "        node_values = load_opinions(opin_path)\n",
    "        nx.set_node_attributes(G, node_values, name='value')\n",
    "        graphs.append(G)\n",
    "        opinions_list.append(node_values)\n",
    "    return graphs, opinions_list\n",
    "\n",
    "# --- Clustering and layout ---\n",
    "def custom_cluster_detection(G, node_values, layout):\n",
    "    nodes = list(G.nodes)\n",
    "    clusters = []\n",
    "    unvisited = set(nodes)\n",
    "    while unvisited:\n",
    "        current = unvisited.pop()\n",
    "        cluster = {current}\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            to_check = unvisited.copy()\n",
    "            for other in to_check:\n",
    "                all_dist_ok = True\n",
    "                all_val_ok = True\n",
    "                for cnode in cluster:\n",
    "                    pos_c = layout[cnode]\n",
    "                    pos_o = layout[other]\n",
    "                    dist = np.linalg.norm(np.array(pos_c) - np.array(pos_o))\n",
    "                    if dist >= 3:\n",
    "                        all_dist_ok = False\n",
    "                        break\n",
    "                for cnode in cluster:\n",
    "                    if abs(node_values[cnode] - node_values[other]) >= 0.3:\n",
    "                        all_val_ok = False\n",
    "                        break\n",
    "                if all_dist_ok and all_val_ok:\n",
    "                    cluster.add(other)\n",
    "                    unvisited.remove(other)\n",
    "                    changed = True\n",
    "        clusters.append(cluster)\n",
    "    # Filter clusters to have min size 3\n",
    "    clusters = [c for c in clusters if len(c) >= 3]\n",
    "    cluster_map = {}\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        for n in cluster:\n",
    "            cluster_map[n] = i\n",
    "    return cluster_map\n",
    "\n",
    "def detect_clusters_custom(graphs, opinions_list):\n",
    "    cluster_assignments = []\n",
    "    global_layouts = []\n",
    "    for i, G in enumerate(graphs):\n",
    "        layout = nx.spring_layout(G, weight='weight', k=0.5, iterations=50)\n",
    "        node_values = opinions_list[i]\n",
    "        cluster_map = custom_cluster_detection(G, node_values, layout)\n",
    "        cluster_assignments.append(cluster_map)\n",
    "        global_layouts.append(layout)\n",
    "    return cluster_assignments, global_layouts\n",
    "\n",
    "def avoid_node_overlap(layout, node_sizes, min_dist_factor=2.5, iterations=50):\n",
    "    positions = {n: np.array(pos) for n, pos in layout.items()}\n",
    "    nodes = list(layout.keys())\n",
    "    for _ in range(iterations):\n",
    "        moved = False\n",
    "        for i, n1 in enumerate(nodes):\n",
    "            for n2 in nodes[i+1:]:\n",
    "                pos1, pos2 = positions[n1], positions[n2]\n",
    "                diff = pos2 - pos1\n",
    "                dist = np.linalg.norm(diff)\n",
    "                min_dist = (node_sizes[n1] + node_sizes[n2]) * min_dist_factor\n",
    "                if dist < min_dist and dist > 1e-6:\n",
    "                    overlap = min_dist - dist\n",
    "                    shift = (overlap / 2) * (diff / dist)\n",
    "                    positions[n1] -= shift\n",
    "                    positions[n2] += shift\n",
    "                    moved = True\n",
    "        if not moved:\n",
    "            break\n",
    "    return {n: pos.tolist() for n, pos in positions.items()}\n",
    "\n",
    "def scale_and_fit_layout(layout, width=1280, height=720, margin=50):\n",
    "    pos_arr = np.array(list(layout.values()))\n",
    "    min_xy = pos_arr.min(axis=0)\n",
    "    max_xy = pos_arr.max(axis=0)\n",
    "    size = max_xy - min_xy\n",
    "    scale_x = (width - 2 * margin) / size[0] if size[0] > 0 else 1.0\n",
    "    scale_y = (height - 2 * margin) / size[1] if size[1] > 0 else 1.0\n",
    "    scale = min(scale_x, scale_y)\n",
    "    new_layout = {}\n",
    "    for n, pos in layout.items():\n",
    "        norm_pos = (np.array(pos) - min_xy) * scale + margin\n",
    "        new_layout[n] = norm_pos.tolist()\n",
    "    return new_layout\n",
    "\n",
    "def generate_layouts(graphs, cluster_assignments, opinions_list):\n",
    "    layouts = []\n",
    "    for t, G in enumerate(graphs):\n",
    "        node_values = opinions_list[t]\n",
    "        cluster_map = cluster_assignments[t]\n",
    "        cluster_positions = {}\n",
    "\n",
    "        # Use only nodes present in cluster_map for clusters\n",
    "        clusters_ids = set(cluster_map.values())\n",
    "        for cluster_id in clusters_ids:\n",
    "            nodes = [n for n in G.nodes if cluster_map.get(n) == cluster_id]\n",
    "            if not nodes:\n",
    "                continue\n",
    "            subgraph = G.subgraph(nodes)\n",
    "            sublayout = nx.spring_layout(subgraph, weight='weight', k=0.5, iterations=50)\n",
    "            scale = 1.0\n",
    "            for n in sublayout:\n",
    "                sublayout[n] = scale * np.array(sublayout[n])\n",
    "            offset = np.random.rand(2) * 10\n",
    "            for n in sublayout:\n",
    "                sublayout[n] = sublayout[n] + offset\n",
    "            cluster_positions.update(sublayout)\n",
    "\n",
    "        # For nodes not assigned to any cluster, just assign them random positions\n",
    "        unclustered_nodes = [n for n in G.nodes if n not in cluster_map]\n",
    "        for n in unclustered_nodes:\n",
    "            cluster_positions[n] = np.random.rand(2) * 10\n",
    "\n",
    "        node_sizes = {n: 2 * (10 * abs(node_values.get(n, 0)) + 20) for n in G.nodes}  # diameter\n",
    "        layout_no_overlap = avoid_node_overlap(cluster_positions, node_sizes)\n",
    "        layout_scaled = scale_and_fit_layout(layout_no_overlap)\n",
    "        layouts.append(layout_scaled)\n",
    "    return layouts\n",
    "\n",
    "# --- Visual helpers ---\n",
    "def generate_minimal_alpha_boundary(cluster_nodes, G, layout, node_sizes, padding=5):\n",
    "    shapes = []\n",
    "\n",
    "    # Add node circles (using radius = size/2)\n",
    "    for n in cluster_nodes:\n",
    "        center = layout[n]\n",
    "        radius = node_sizes.get(n, 40) / 2  # default max radius if missing\n",
    "        circle = Point(center).buffer(radius)\n",
    "        shapes.append(circle)\n",
    "\n",
    "    # Add edges as thickened lines (buffered by small thickness, e.g. 1.5)\n",
    "    subgraph = G.subgraph(cluster_nodes)\n",
    "    for u, v in subgraph.edges():\n",
    "        p0 = layout[u]\n",
    "        p1 = layout[v]\n",
    "        line = LineString([p0, p1])\n",
    "        line_buffer = line.buffer(1.5)\n",
    "        shapes.append(line_buffer)\n",
    "\n",
    "    # Combine all shapes (nodes + edges)\n",
    "    combined_shape = unary_union(shapes)\n",
    "\n",
    "    # Buffer by padding\n",
    "    hull = combined_shape.buffer(padding)\n",
    "\n",
    "    if hull.is_empty or not hull.exterior:\n",
    "        return []\n",
    "\n",
    "    x, y = hull.exterior.xy\n",
    "    return list(zip(x, y))\n",
    "\n",
    "def bezier_curve_points(p0, p1, control, num=20):\n",
    "    points = []\n",
    "    for t in np.linspace(0, 1, num):\n",
    "        point = (1 - t) ** 2 * np.array(p0) + 2 * (1 - t) * t * np.array(control) + t ** 2 * np.array(p1)\n",
    "        points.append(point.tolist())\n",
    "    return points\n",
    "\n",
    "def build_curvy_edge_trace(G, layout):\n",
    "    edge_x, edge_y = [], []\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        p0 = layout[u]\n",
    "        p1 = layout[v]\n",
    "        mid = (np.array(p0) + np.array(p1)) / 2\n",
    "        vec = np.array(p1) - np.array(p0)\n",
    "        perp = np.array([-vec[1], vec[0]])\n",
    "        norm_perp = perp / (np.linalg.norm(perp) + 1e-6)\n",
    "        offset = norm_perp * np.linalg.norm(vec) * 0.3\n",
    "        control = mid + offset\n",
    "        curve_points = bezier_curve_points(p0, p1, control)\n",
    "        xs, ys = zip(*curve_points)\n",
    "        edge_x.extend(xs + (None,))\n",
    "        edge_y.extend(ys + (None,))\n",
    "    return edge_x, edge_y\n",
    "\n",
    "def create_node_trace(G, layout, node_values, cluster_map):\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_color = []\n",
    "    node_size = []\n",
    "    for node in G.nodes():\n",
    "        pos = layout[node]\n",
    "        node_x.append(pos[0])\n",
    "        node_y.append(pos[1])\n",
    "        val = node_values.get(node, 0)\n",
    "        node_color.append(val)\n",
    "        # Node size between 20 and 40 diameter (radius 10 to 20)\n",
    "        size = 20 * abs(val) + 20\n",
    "        size = max(20, min(size, 40))\n",
    "        node_size.append(size)\n",
    "    trace = go.Scatter(\n",
    "        x=node_x, y=node_y,\n",
    "        mode='markers+text',\n",
    "        text=[str(n) for n in G.nodes()],\n",
    "        textposition=\"top center\",\n",
    "        marker=dict(\n",
    "            size=node_size,\n",
    "            color=node_color,\n",
    "            colorscale='RdBu',\n",
    "            cmin=-1, cmax=1,\n",
    "            line_width=1,\n",
    "            line_color='black'\n",
    "        )\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "def create_boundary_trace(points, cluster_id):\n",
    "    if not points:\n",
    "        return None\n",
    "    xs, ys = zip(*points)\n",
    "    trace = go.Scatter(\n",
    "        x=xs, y=ys,\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(0,200,0,0.15)',\n",
    "        line=dict(color='rgba(0,0,0,0)', width=0),\n",
    "        hoverinfo='skip',\n",
    "        showlegend=False,\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "def create_frame(G, layout, node_values, cluster_map):\n",
    "    fig = go.Figure()\n",
    "    node_sizes = {n: 20 * abs(node_values.get(n, 0)) + 20 for n in G.nodes()}\n",
    "    node_sizes = {n: max(20, min(size, 40)) for n, size in node_sizes.items()}\n",
    "    \n",
    "    clusters = {}\n",
    "    for n, c in cluster_map.items():\n",
    "        clusters.setdefault(c, []).append(n)\n",
    "\n",
    "    for c_id, nodes in clusters.items():\n",
    "        boundary = generate_minimal_alpha_boundary(nodes, G, layout, node_sizes, padding=5)\n",
    "        btrace = create_boundary_trace(boundary, c_id)\n",
    "        if btrace:\n",
    "            fig.add_trace(btrace)\n",
    "\n",
    "    edge_x, edge_y = build_curvy_edge_trace(G, layout)\n",
    "    edge_trace = go.Scatter(x=edge_x, y=edge_y, mode='lines',\n",
    "                            line=dict(color='rgba(150,150,150,0.7)', width=1),\n",
    "                            hoverinfo='none')\n",
    "    fig.add_trace(edge_trace)\n",
    "\n",
    "    node_trace = create_node_trace(G, layout, node_values, cluster_map)\n",
    "    fig.add_trace(node_trace)\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 1280]),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 720], scaleanchor=\"x\"),\n",
    "        plot_bgcolor='white',\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        width=1280,\n",
    "        height=720,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- Main ---\n",
    "def main(folder_path, output_video_path):\n",
    "    print(\"Loading graph series...\")\n",
    "    graphs, opinions_list = load_graph_series(folder_path)\n",
    "    print(f\"Loaded {len(graphs)} graphs.\")\n",
    "\n",
    "    print(\"Detecting clusters...\")\n",
    "    cluster_assignments, base_layouts = detect_clusters_custom(graphs, opinions_list)\n",
    "    print(\"Cluster detection done.\")\n",
    "\n",
    "    print(\"Generating layouts...\")\n",
    "    layouts = generate_layouts(graphs, cluster_assignments, opinions_list)\n",
    "    print(\"Layouts generated.\")\n",
    "\n",
    "    # Only generate the first frame\n",
    "    print(\"Generating initial frame only...\")\n",
    "    layout = layouts[0]\n",
    "    G = graphs[0]\n",
    "    node_values = opinions_list[0]\n",
    "    cluster_map = cluster_assignments[0]\n",
    "    fig = create_frame(G, layout, node_values, cluster_map)\n",
    "    fig.write_image(\"initial_frame.png\", width=1280, height=720, scale=1)\n",
    "    print(\"Initial frame saved as 'initial_frame.png'\")\n",
    "\n",
    "# Example usage:\n",
    "main('./simls_raw_data/2025-07-08_16-37-25', 'output.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a1622b8-7325-4104-be78-6720e7587e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graphs and opinions...\n",
      "Loaded 73 graphs.\n",
      "Detecting clusters...\n",
      "Cluster detection done.\n",
      "Generating layouts...\n",
      "Layouts generated.\n",
      "Initial frame saved as 'initial_frame.png'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import alphashape\n",
    "from shapely.geometry import Polygon, Point, LineString, MultiPolygon\n",
    "import cv2  # For video writing\n",
    "import tempfile\n",
    "\n",
    "# --- Loading functions ---\n",
    "def load_custom_graph(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    num_nodes, is_directed = map(int, lines[0].strip().split(','))\n",
    "    G = nx.DiGraph() if is_directed else nx.Graph()\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "\n",
    "    edge_pattern = re.compile(r\"\\((\\d+),(\\d+),([0-9.]+)\\)\")\n",
    "    for line in lines[1:]:\n",
    "        match = edge_pattern.match(line.strip())\n",
    "        if match:\n",
    "            u, v, w = int(match[1]), int(match[2]), float(match[3])\n",
    "            G.add_edge(u, v, weight=w)\n",
    "    return G, num_nodes\n",
    "\n",
    "def load_opinions(filepath):\n",
    "    node_values = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                node, val = int(parts[0]), float(parts[1])\n",
    "                node_values[node] = val\n",
    "    return node_values\n",
    "\n",
    "def load_graph_series(folder_path):\n",
    "    graph_files = sorted(f for f in os.listdir(folder_path) if f.endswith('.graph'))\n",
    "    graphs = []\n",
    "    opinions_list = []\n",
    "    for gf in graph_files:\n",
    "        graph_path = os.path.join(folder_path, gf)\n",
    "        opin_path = graph_path.replace('.graph', '.opinions')\n",
    "        G, num_nodes = load_custom_graph(graph_path)\n",
    "        node_values = load_opinions(opin_path)\n",
    "        nx.set_node_attributes(G, node_values, name='value')\n",
    "        graphs.append(G)\n",
    "        opinions_list.append(node_values)\n",
    "    return graphs, opinions_list\n",
    "\n",
    "# --- Clustering and layout ---\n",
    "def custom_cluster_detection(G, node_values, layout):\n",
    "    nodes = list(G.nodes)\n",
    "    clusters = []\n",
    "    unvisited = set(nodes)\n",
    "    while unvisited:\n",
    "        current = unvisited.pop()\n",
    "        cluster = {current}\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            to_check = unvisited.copy()\n",
    "            for other in to_check:\n",
    "                all_dist_ok = True\n",
    "                all_val_ok = True\n",
    "                for cnode in cluster:\n",
    "                    pos_c = layout[cnode]\n",
    "                    pos_o = layout[other]\n",
    "                    dist = np.linalg.norm(np.array(pos_c) - np.array(pos_o))\n",
    "                    if dist >= 3:\n",
    "                        all_dist_ok = False\n",
    "                        break\n",
    "                for cnode in cluster:\n",
    "                    if abs(node_values[cnode] - node_values[other]) >= 0.3:\n",
    "                        all_val_ok = False\n",
    "                        break\n",
    "                if all_dist_ok and all_val_ok:\n",
    "                    cluster.add(other)\n",
    "                    unvisited.remove(other)\n",
    "                    changed = True\n",
    "        clusters.append(cluster)\n",
    "    # Filter clusters by min size = 3\n",
    "    clusters = [c for c in clusters if len(c) >= 3]\n",
    "    cluster_map = {}\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        for n in cluster:\n",
    "            cluster_map[n] = i\n",
    "    # For nodes not in any cluster assign unique cluster to avoid KeyErrors later\n",
    "    no_cluster_id = len(clusters)\n",
    "    for n in G.nodes:\n",
    "        if n not in cluster_map:\n",
    "            cluster_map[n] = no_cluster_id\n",
    "            no_cluster_id += 1\n",
    "    return cluster_map\n",
    "\n",
    "def detect_clusters_custom(graphs, opinions_list):\n",
    "    cluster_assignments = []\n",
    "    global_layouts = []\n",
    "    for i, G in enumerate(graphs):\n",
    "        layout = nx.spring_layout(G, weight='weight', k=0.5, iterations=50)\n",
    "        node_values = opinions_list[i]\n",
    "        cluster_map = custom_cluster_detection(G, node_values, layout)\n",
    "        cluster_assignments.append(cluster_map)\n",
    "        global_layouts.append(layout)\n",
    "    return cluster_assignments, global_layouts\n",
    "\n",
    "def avoid_node_overlap(layout, node_sizes, min_dist_factor=2.5, iterations=50):\n",
    "    positions = {n: np.array(pos) for n, pos in layout.items()}\n",
    "    nodes = list(layout.keys())\n",
    "    for _ in range(iterations):\n",
    "        moved = False\n",
    "        for i, n1 in enumerate(nodes):\n",
    "            for n2 in nodes[i+1:]:\n",
    "                pos1, pos2 = positions[n1], positions[n2]\n",
    "                diff = pos2 - pos1\n",
    "                dist = np.linalg.norm(diff)\n",
    "                min_dist = (node_sizes[n1] + node_sizes[n2]) * min_dist_factor\n",
    "                if dist < min_dist and dist > 1e-6:\n",
    "                    overlap = min_dist - dist\n",
    "                    shift = (overlap / 2) * (diff / dist)\n",
    "                    positions[n1] -= shift\n",
    "                    positions[n2] += shift\n",
    "                    moved = True\n",
    "        if not moved:\n",
    "            break\n",
    "    return {n: pos.tolist() for n, pos in positions.items()}\n",
    "\n",
    "def scale_and_fit_layout(layout, width=1280, height=720, margin=50):\n",
    "    pos_arr = np.array(list(layout.values()))\n",
    "    min_xy = pos_arr.min(axis=0)\n",
    "    max_xy = pos_arr.max(axis=0)\n",
    "    size = max_xy - min_xy\n",
    "    scale_x = (width - 2 * margin) / size[0] if size[0] > 0 else 1.0\n",
    "    scale_y = (height - 2 * margin) / size[1] if size[1] > 0 else 1.0\n",
    "    scale = min(scale_x, scale_y)\n",
    "    new_layout = {}\n",
    "    for n, pos in layout.items():\n",
    "        norm_pos = (np.array(pos) - min_xy) * scale + margin\n",
    "        new_layout[n] = norm_pos.tolist()\n",
    "    return new_layout\n",
    "\n",
    "def generate_layouts(graphs, cluster_assignments, opinions_list):\n",
    "    layouts = []\n",
    "    for t, G in enumerate(graphs):\n",
    "        node_values = opinions_list[t]\n",
    "        cluster_map = cluster_assignments[t]\n",
    "        cluster_positions = {}\n",
    "        for cluster_id in set(cluster_map.values()):\n",
    "            nodes = [n for n in G.nodes if cluster_map[n] == cluster_id]\n",
    "            subgraph = G.subgraph(nodes)\n",
    "            sublayout = nx.spring_layout(subgraph, weight='weight', k=0.5, iterations=50)\n",
    "            scale = 1.0\n",
    "            for n in sublayout:\n",
    "                sublayout[n] = scale * np.array(sublayout[n])\n",
    "            offset = np.random.rand(2) * 10\n",
    "            for n in sublayout:\n",
    "                sublayout[n] = sublayout[n] + offset\n",
    "            cluster_positions.update(sublayout)\n",
    "        node_sizes = {n: np.clip(10 * abs(node_values.get(n, 0)) + 20, 20, 40) for n in G.nodes}\n",
    "        layout_no_overlap = avoid_node_overlap(cluster_positions, node_sizes)\n",
    "        layout_scaled = scale_and_fit_layout(layout_no_overlap)\n",
    "        layouts.append(layout_scaled)\n",
    "    return layouts\n",
    "\n",
    "# --- Visual helpers ---\n",
    "def generate_minimal_alpha_boundary(cluster_nodes, G, layout, node_sizes, padding=5):\n",
    "    node_circles = []\n",
    "    for n in cluster_nodes:\n",
    "        x, y = layout[n]\n",
    "        r = node_sizes.get(n, 20) / 2\n",
    "        circle = Point(x, y).buffer(r)\n",
    "        node_circles.append(circle)\n",
    "\n",
    "    edge_polygons = []\n",
    "    for u, v in G.edges():\n",
    "        if u in cluster_nodes and v in cluster_nodes:\n",
    "            line = LineString([layout[u], layout[v]]).buffer(2)\n",
    "            edge_polygons.append(line)\n",
    "\n",
    "    combined_shape = node_circles[0]\n",
    "    for shape in node_circles[1:] + edge_polygons:\n",
    "        combined_shape = combined_shape.union(shape)\n",
    "\n",
    "    hull = combined_shape.buffer(padding)\n",
    "\n",
    "    if hull.is_empty:\n",
    "        return []\n",
    "    if isinstance(hull, MultiPolygon):\n",
    "        hull = max(hull.geoms, key=lambda p: p.area)\n",
    "\n",
    "    x, y = hull.exterior.xy\n",
    "    return list(zip(x, y))\n",
    "\n",
    "def bezier_curve_points(p0, p1, control, num=20):\n",
    "    points = []\n",
    "    for t in np.linspace(0, 1, num):\n",
    "        point = (1 - t) ** 2 * np.array(p0) + 2 * (1 - t) * t * np.array(control) + t ** 2 * np.array(p1)\n",
    "        points.append(point.tolist())\n",
    "    return points\n",
    "\n",
    "def build_curvy_edge_trace(G, layout):\n",
    "    edge_x, edge_y = [], []\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        p0 = layout[u]\n",
    "        p1 = layout[v]\n",
    "        mid = (np.array(p0) + np.array(p1)) / 2\n",
    "        vec = np.array(p1) - np.array(p0)\n",
    "        perp = np.array([-vec[1], vec[0]])\n",
    "        norm_perp = perp / (np.linalg.norm(perp) + 1e-6)\n",
    "        offset = norm_perp * np.linalg.norm(vec) * 0.3\n",
    "        control = mid + offset\n",
    "        curve_points = bezier_curve_points(p0, p1, control)\n",
    "        xs, ys = zip(*curve_points)\n",
    "        edge_x.extend(xs + (None,))\n",
    "        edge_y.extend(ys + (None,))\n",
    "    return edge_x, edge_y\n",
    "\n",
    "def create_node_trace(G, layout, node_values, cluster_map):\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_color = []\n",
    "    node_size = []\n",
    "    for node in G.nodes():\n",
    "        pos = layout[node]\n",
    "        node_x.append(pos[0])\n",
    "        node_y.append(pos[1])\n",
    "        val = node_values.get(node, 0)\n",
    "        node_color.append(val)\n",
    "        node_size.append(np.clip(10 * abs(val) + 20, 20, 40))\n",
    "    trace = go.Scatter(\n",
    "        x=node_x, y=node_y,\n",
    "        mode='markers+text',\n",
    "        text=[str(n) for n in G.nodes()],\n",
    "        textposition=\"top center\",\n",
    "        marker=dict(\n",
    "            size=node_size,\n",
    "            color=node_color,\n",
    "            colorscale='RdBu',\n",
    "            cmin=-1, cmax=1,\n",
    "            line_width=1,\n",
    "            line_color='black'\n",
    "        )\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "def create_boundary_trace(points, cluster_id):\n",
    "    if not points:\n",
    "        return None\n",
    "    xs, ys = zip(*points)\n",
    "    trace = go.Scatter(\n",
    "        x=xs, y=ys,\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(0,200,0,0.15)',\n",
    "        line=dict(color='rgba(0,0,0,0)', width=0),\n",
    "        hoverinfo='skip',\n",
    "        showlegend=False,\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "def create_frame(G, layout, node_values, cluster_map):\n",
    "    fig = go.Figure()\n",
    "    clusters = {}\n",
    "    for n, c in cluster_map.items():\n",
    "        clusters.setdefault(c, []).append(n)\n",
    "\n",
    "    node_sizes = {n: np.clip(10 * abs(node_values.get(n, 0)) + 20, 20, 40) for n in G.nodes}\n",
    "\n",
    "    for c_id, nodes in clusters.items():\n",
    "        boundary = generate_minimal_alpha_boundary(nodes, G, layout, node_sizes, padding=5)\n",
    "        btrace = create_boundary_trace(boundary, c_id)\n",
    "        if btrace:\n",
    "            fig.add_trace(btrace)\n",
    "\n",
    "    # Build edge trace with edge widths proportional to 1 - edge weight, min 3 max 10\n",
    "    edge_x, edge_y = [], []\n",
    "    widths = []\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        p0 = layout[u]\n",
    "        p1 = layout[v]\n",
    "        mid = (np.array(p0) + np.array(p1)) / 2\n",
    "        vec = np.array(p1) - np.array(p0)\n",
    "        perp = np.array([-vec[1], vec[0]])\n",
    "        norm_perp = perp / (np.linalg.norm(perp) + 1e-6)\n",
    "        offset = norm_perp * np.linalg.norm(vec) * 0.3\n",
    "        control = mid + offset\n",
    "        curve_points = bezier_curve_points(p0, p1, control)\n",
    "        xs, ys = zip(*curve_points)\n",
    "        edge_x.extend(xs + (None,))\n",
    "        edge_y.extend(ys + (None,))\n",
    "        edge_width = 3 + (1 - d['weight']) * (10 - 3)  # min 3 max 10, proportional to 1-edge_weight\n",
    "        widths.append(edge_width)\n",
    "\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x, y=edge_y,\n",
    "        mode='lines',\n",
    "        line=dict(color='rgba(150,150,150,0.7)', width=3),  # We'll override widths below manually\n",
    "        hoverinfo='none',\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.add_trace(edge_trace)\n",
    "\n",
    "    # Add nodes on top\n",
    "    node_trace = create_node_trace(G, layout, node_values, cluster_map)\n",
    "    fig.add_trace(node_trace)\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
    "        plot_bgcolor='white',\n",
    "        margin=dict(l=20, r=20, t=20, b=20),\n",
    "        hovermode='closest',\n",
    "        width=1280,\n",
    "        height=720,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# --- Main ---\n",
    "def main(folder_path, output_video_path):\n",
    "    print(\"Loading graphs and opinions...\")\n",
    "    graphs, opinions_list = load_graph_series(folder_path)\n",
    "    print(f\"Loaded {len(graphs)} graphs.\")\n",
    "\n",
    "    print(\"Detecting clusters...\")\n",
    "    cluster_assignments, layouts = detect_clusters_custom(graphs, opinions_list)\n",
    "    print(\"Cluster detection done.\")\n",
    "\n",
    "    print(\"Generating layouts...\")\n",
    "    layouts = generate_layouts(graphs, cluster_assignments, opinions_list)\n",
    "    print(\"Layouts generated.\")\n",
    "\n",
    "    # Generate first frame as example\n",
    "    G = graphs[0]\n",
    "    layout = layouts[0]\n",
    "    node_values = opinions_list[0]\n",
    "    cluster_map = cluster_assignments[0]\n",
    "\n",
    "    fig = create_frame(G, layout, node_values, cluster_map)\n",
    "    fig.write_image(\"initial_frame.png\", width=1280, height=720, scale=1)\n",
    "    print(\"Initial frame saved as 'initial_frame.png'\")\n",
    "\n",
    "    # You can extend this part to generate video frames and write to video with cv2.VideoWriter\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    main('./simls_raw_data/2025-07-08_16-37-25', 'output.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36afe3de-e131-437d-8575-593926dc0a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graphs and opinions...\n",
      "Loaded 73 graphs.\n",
      "Detecting clusters...\n",
      "Cluster detection done.\n",
      "Generating layouts...\n",
      "Layouts generated.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "generate_minimal_alpha_boundary() got an unexpected keyword argument 'padding'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 354\u001b[39m\n\u001b[32m    351\u001b[39m     \u001b[38;5;66;03m# Video generation can be implemented here...\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m      \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./simls_raw_data/2025-07-08_16-37-25\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutput.mp4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 346\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(folder_path, output_video_path)\u001b[39m\n\u001b[32m    343\u001b[39m node_values = opinions_list[i]\n\u001b[32m    344\u001b[39m cluster_map = cluster_assignments[i]\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m fig = \u001b[43mcreate_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mframe_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_4k.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    348\u001b[39m fig.write_image(filename, width=\u001b[32m3840\u001b[39m, height=\u001b[32m2160\u001b[39m, scale=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 275\u001b[39m, in \u001b[36mcreate_frame\u001b[39m\u001b[34m(G, layout, node_values, cluster_map)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(nodes) < \u001b[32m3\u001b[39m:  \u001b[38;5;66;03m# <-- Here, only clusters with 3 or more nodes get hulls\u001b[39;00m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m hull_coords = \u001b[43mgenerate_minimal_alpha_boundary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hull_coords:\n\u001b[32m    277\u001b[39m     x, y = \u001b[38;5;28mzip\u001b[39m(*hull_coords)\n",
      "\u001b[31mTypeError\u001b[39m: generate_minimal_alpha_boundary() got an unexpected keyword argument 'padding'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import alphashape\n",
    "from shapely.geometry import Point, LineString, MultiPolygon\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Loading functions ---\n",
    "def load_custom_graph(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    num_nodes, is_directed = map(int, lines[0].strip().split(','))\n",
    "    G = nx.DiGraph() if is_directed else nx.Graph()\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "    edge_pattern = re.compile(r\"\\((\\d+),(\\d+),([0-9.]+)\\)\")\n",
    "    for line in lines[1:]:\n",
    "        match = edge_pattern.match(line.strip())\n",
    "        if match:\n",
    "            u, v, w = int(match[1]), int(match[2]), float(match[3])\n",
    "            G.add_edge(u, v, weight=w)\n",
    "    return G, num_nodes\n",
    "\n",
    "def load_opinions(filepath):\n",
    "    node_values = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                node, val = int(parts[0]), float(parts[1])\n",
    "                node_values[node] = val\n",
    "    return node_values\n",
    "\n",
    "def load_graph_series(folder_path):\n",
    "    graph_files = sorted(f for f in os.listdir(folder_path) if f.endswith('.graph'))\n",
    "    graphs, opinions_list = [], []\n",
    "    for gf in graph_files:\n",
    "        graph_path = os.path.join(folder_path, gf)\n",
    "        opin_path = graph_path.replace('.graph', '.opinions')\n",
    "        G, _ = load_custom_graph(graph_path)\n",
    "        node_values = load_opinions(opin_path)\n",
    "        nx.set_node_attributes(G, node_values, name='value')\n",
    "        graphs.append(G)\n",
    "        opinions_list.append(node_values)\n",
    "    return graphs, opinions_list\n",
    "\n",
    "# --- Clustering and layout ---\n",
    "def custom_cluster_detection(G, node_values, layout):\n",
    "    nodes = list(G.nodes)\n",
    "    clusters = []\n",
    "    unvisited = set(nodes)\n",
    "    while unvisited:\n",
    "        current = unvisited.pop()\n",
    "        cluster = {current}\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            to_check = unvisited.copy()\n",
    "            for other in to_check:\n",
    "                all_dist_ok = all(np.linalg.norm(np.array(layout[c]) - np.array(layout[other])) < 3 for c in cluster)\n",
    "                all_val_ok = all(abs(node_values[c] - node_values[other]) < 0.3 for c in cluster)\n",
    "                if all_dist_ok and all_val_ok:\n",
    "                    cluster.add(other)\n",
    "                    unvisited.remove(other)\n",
    "                    changed = True\n",
    "        clusters.append(cluster)\n",
    "    clusters = [c for c in clusters if len(c) >= 3]\n",
    "    cluster_map = {n: i for i, cluster in enumerate(clusters) for n in cluster}\n",
    "    no_cluster_id = len(clusters)\n",
    "    for n in G.nodes:\n",
    "        if n not in cluster_map:\n",
    "            cluster_map[n] = no_cluster_id\n",
    "            no_cluster_id += 1\n",
    "    return cluster_map\n",
    "\n",
    "def detect_clusters_custom(graphs, opinions_list):\n",
    "    cluster_assignments, global_layouts = [], []\n",
    "    for i, G in enumerate(graphs):\n",
    "        layout = nx.spring_layout(G, weight='weight', k=0.5, iterations=50)\n",
    "        node_values = opinions_list[i]\n",
    "        cluster_map = custom_cluster_detection(G, node_values, layout)\n",
    "        cluster_assignments.append(cluster_map)\n",
    "        global_layouts.append(layout)\n",
    "    return cluster_assignments, global_layouts\n",
    "\n",
    "def avoid_node_overlap(layout, node_sizes, min_dist_factor=2.5, iterations=50):\n",
    "    positions = {n: np.array(pos) for n, pos in layout.items()}\n",
    "    nodes = list(layout.keys())\n",
    "    for _ in range(iterations):\n",
    "        moved = False\n",
    "        for i, n1 in enumerate(nodes):\n",
    "            for n2 in nodes[i+1:]:\n",
    "                pos1, pos2 = positions[n1], positions[n2]\n",
    "                diff = pos2 - pos1\n",
    "                dist = np.linalg.norm(diff)\n",
    "                min_dist = (node_sizes[n1] + node_sizes[n2]) * min_dist_factor\n",
    "                if dist < min_dist and dist > 1e-6:\n",
    "                    shift = (min_dist - dist) / 2 * diff / dist\n",
    "                    positions[n1] -= shift\n",
    "                    positions[n2] += shift\n",
    "                    moved = True\n",
    "        if not moved:\n",
    "            break\n",
    "    return {n: pos.tolist() for n, pos in positions.items()}\n",
    "\n",
    "def scale_and_fit_layout(layout, width=3840, height=2160, margin=50):\n",
    "    pos_arr = np.array(list(layout.values()))\n",
    "    min_xy, max_xy = pos_arr.min(axis=0), pos_arr.max(axis=0)\n",
    "    size = max_xy - min_xy\n",
    "    scale = min((width - 2 * margin) / size[0], (height - 2 * margin) / size[1]) if all(size) else 1.0\n",
    "    return {n: ((np.array(pos) - min_xy) * scale + margin).tolist() for n, pos in layout.items()}\n",
    "\n",
    "def generate_layouts(graphs, cluster_assignments, opinions_list):\n",
    "    layouts = []\n",
    "    for t, G in enumerate(graphs):\n",
    "        node_values = opinions_list[t]\n",
    "        cluster_map = cluster_assignments[t]\n",
    "        cluster_positions = {}\n",
    "        for cluster_id in set(cluster_map.values()):\n",
    "            nodes = [n for n in G.nodes if cluster_map[n] == cluster_id]\n",
    "            sublayout = nx.spring_layout(G.subgraph(nodes), weight='weight', k=0.5, iterations=50)\n",
    "            offset = np.random.rand(2) * 10\n",
    "            for n in sublayout:\n",
    "                cluster_positions[n] = np.array(sublayout[n]) + offset\n",
    "        def scale_size(val): return 60 + np.clip((abs(val) - 0.0) / 1.0, 0, 1) * (120 - 60)\n",
    "        node_sizes = {n: scale_size(node_values.get(n, 0)) for n in G.nodes}\n",
    "        layout_no_overlap = avoid_node_overlap(cluster_positions, node_sizes)\n",
    "        layout_scaled = scale_and_fit_layout(layout_no_overlap)\n",
    "        layouts.append(layout_scaled)\n",
    "    return layouts\n",
    "\n",
    "# --- Visual helpers ---\n",
    "def generate_minimal_alpha_boundary(cluster_nodes, G, layout, node_sizes, alpha=20):\n",
    "    points = []\n",
    "    for n in cluster_nodes:\n",
    "        x, y = layout[n]\n",
    "        r = node_sizes.get(n, 60) / 2\n",
    "        circle = Point(x, y).buffer(r)\n",
    "        points.extend(list(circle.exterior.coords))\n",
    "    for u, v in G.edges():\n",
    "        if u in cluster_nodes and v in cluster_nodes:\n",
    "            line = LineString([layout[u], layout[v]]).buffer(3)\n",
    "            points.extend(list(line.exterior.coords))\n",
    "    if len(points) < 4:\n",
    "        return []\n",
    "    shape = alphashape.alphashape(points, alpha)\n",
    "    if shape.is_empty:\n",
    "        return []\n",
    "    if isinstance(shape, MultiPolygon):\n",
    "        shape = max(shape.geoms, key=lambda p: p.area)\n",
    "    return list(zip(*shape.exterior.xy))\n",
    "\n",
    "def bezier_curve_points(p0, p1, control, num=20):\n",
    "    return [(1 - t)**2 * np.array(p0) + 2 * (1 - t) * t * np.array(control) + t**2 * np.array(p1) for t in np.linspace(0, 1, num)]\n",
    "\n",
    "def create_node_trace(G, layout, node_values, cluster_map):\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    cluster_colors = {cid: f\"hsl({random.randint(0,360)},50%,50%)\" for cid in set(cluster_map.values())}\n",
    "    node_x, node_y, node_color, node_size = [], [], [], []\n",
    "    for n in G.nodes():\n",
    "        x, y = layout[n]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        val = node_values.get(n, 0)\n",
    "        node_color.append(cluster_colors[cluster_map[n]])\n",
    "        size = 60 + np.clip((abs(val) - 0.0) / 1.0, 0, 1) * (120 - 60)\n",
    "        node_size.append(size)\n",
    "    return go.Scatter(\n",
    "        x=node_x, y=node_y, mode='markers',\n",
    "        marker=dict(color=node_color, size=node_size, line=dict(width=2, color='black')),\n",
    "        text=[f'Node {n}: {node_values.get(n, 0):.2f}' for n in G.nodes()],\n",
    "        hoverinfo='text', showlegend=False\n",
    "    )\n",
    "\n",
    "def create_frame(G, layout, node_values, cluster_map):\n",
    "    fig = go.Figure()\n",
    "    clusters = {}\n",
    "    for n, c in cluster_map.items():\n",
    "        clusters.setdefault(c, []).append(n)\n",
    "    def scale_size(val): return 60 + np.clip((abs(val) - 0.0) / 1.0, 0, 1) * (120 - 60)\n",
    "    node_sizes = {n: scale_size(node_values.get(n, 0)) for n in G.nodes}\n",
    "    for c, nodes in clusters.items():\n",
    "        if len(nodes) < 3: continue\n",
    "        hull_coords = generate_minimal_alpha_boundary(nodes, G, layout, node_sizes)\n",
    "        if hull_coords:\n",
    "            x, y = zip(*hull_coords)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x, y=y, fill=\"toself\", fillcolor=\"rgba(0,100,200,0.1)\",\n",
    "                line=dict(color=\"rgba(0,100,200,0.5)\", width=4),\n",
    "                hoverinfo='skip', showlegend=False\n",
    "            ))\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        p0, p1 = layout[u], layout[v]\n",
    "        mid = (np.array(p0) + np.array(p1)) / 2\n",
    "        offset = np.cross(p1 - p0, [0, 0, 1])[:2]\n",
    "        control = mid + offset / (np.linalg.norm(offset) + 1e-6) * np.linalg.norm(np.array(p1) - np.array(p0)) * 0.3\n",
    "        curve_points = bezier_curve_points(p0, p1, control)\n",
    "        xs, ys = zip(*curve_points)\n",
    "        width = 10 + (1 - d['weight']) * 10\n",
    "        fig.add_trace(go.Scatter(x=xs, y=ys, mode='lines', line=dict(color='rgba(150,150,150,0.7)', width=width), hoverinfo='none', showlegend=False))\n",
    "    fig.add_trace(create_node_trace(G, layout, node_values, cluster_map))\n",
    "    fig.update_layout(xaxis=dict(visible=False), yaxis=dict(visible=False),\n",
    "                      plot_bgcolor='white', margin=dict(l=20, r=20, t=20, b=20),\n",
    "                      hovermode='closest', width=3840, height=2160)\n",
    "    return fig\n",
    "\n",
    "# --- Main ---\n",
    "def main(folder_path, output_video_path):\n",
    "    graphs, opinions_list = load_graph_series(folder_path)\n",
    "    print(f\"Loaded {len(graphs)} graphs.\")\n",
    "    cluster_assignments, _ = detect_clusters_custom(graphs, opinions_list)\n",
    "    layouts = generate_layouts(graphs, cluster_assignments, opinions_list)\n",
    "\n",
    "    os.makedirs(\"frames\", exist_ok=True)\n",
    "    frame_paths = []\n",
    "\n",
    "    print(\"Generating frames:\")\n",
    "    for i in tqdm(range(len(graphs))):\n",
    "        G, layout, node_values, cluster_map = graphs[i], layouts[i], opinions_list[i], cluster_assignments[i]\n",
    "        fig = create_frame(G, layout, node_values, cluster_map)\n",
    "        frame_path = os.path.join(\"frames\", f\"frame_{i:04d}.png\")\n",
    "        fig.write_image(frame_path, width=3840, height=2160)\n",
    "        frame_paths.append(frame_path)\n",
    "\n",
    "    print(\"Compiling video...\")\n",
    "    if frame_paths:\n",
    "        first = cv2.imread(frame_paths[0])\n",
    "        height, width, _ = first.shape\n",
    "        video = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), 2, (width, height))\n",
    "        for path in tqdm(frame_paths):\n",
    "            frame = cv2.imread(path)\n",
    "            if frame is not None:\n",
    "                video.write(frame)\n",
    "        video.release()\n",
    "        print(f\"Video saved to: {output_video_path}\")\n",
    "    else:\n",
    "        print(\"No frames generated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage: python script.py <input_folder> <output_video_path>\")\n",
    "    else:\n",
    "        main('./simls_raw_data/2025-07-08_16-37-25', 'output.mp4')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
